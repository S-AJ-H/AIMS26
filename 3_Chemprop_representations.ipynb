{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/S-AJ-H/AIMS26/blob/main/3_Chemprop_representations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Chemprop for predicting polymer properties\n",
        "\n",
        "This workbook introduces the use of Chemprop for predicting chemical properties. Chemprop uses a graph neural network method in which \"message passing\" is used to learn hidden representations of chemicals. These representations are then passed through a feed-forward neural network to predict chemical properties.\n",
        "\n",
        "We again choose to predict the \"electron affinity\" of polymer photocatalysts.\n",
        "\n",
        "You will:\n",
        "   \n",
        "*   Train and evaluate a Chemprop model\n",
        "*   Compare this model to the \"fixed representations\" model from Notebook 1.\n",
        "\n",
        "\n",
        "Resources:\n",
        ">RDKit:   \n",
        ">https://rdkit.org/docs/index.html\n",
        "\n",
        ">Chemprop:  \n",
        ">https://pubs.acs.org/doi/10.1021/acs.jcim.9b00237  \n",
        ">https://pubs.acs.org/doi/10.1021/acs.jcim.3c01250  \n",
        ">https://chemprop.readthedocs.io/en/latest/\n",
        "\n",
        ">Data from:  \n",
        ">https://pubs.acs.org/doi/full/10.1021/jacs.9b03591\n"
      ],
      "metadata": {
        "id": "Jur1pSFyVOu8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3khTEFSKnBNS"
      },
      "source": [
        "##0. Install Chemprop from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4eAu_qknBNU"
      },
      "outputs": [],
      "source": [
        "# Chemprop (~1min)\n",
        "!pip install chemprop -qq\n",
        "import chemprop\n",
        "print(\"Imported Chemprop version\", chemprop.__version__)\n",
        "\n",
        "from rdkit import Chem                                                  # rdkit is used to convert SMILES to molecular graphs (\"mols\")\n",
        "from rdkit.Chem import Draw                                             # Lets us draw molecules\n",
        "from chemprop import data, featurizers, models, nn                      # chemprop is our GNN package\n",
        "\n",
        "# ML\n",
        "import lightning.pytorch as pl                                          # lightning has built-in functions for lots of the basics (metric tracking etc); Chemprop is built on this.\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from lightning.pytorch.loggers import CSVLogger                         # Configure CSV logger for tracking losses\n",
        "import logging\n",
        "logging.getLogger(\"lightning.pytorch\").setLevel(logging.ERROR)\n",
        "from sklearn.model_selection import train_test_split, KFold, PredefinedSplit\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "# Misc\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "version = 0                                                             # used for save files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrEf3rQznBNW"
      },
      "source": [
        "##1. Load data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwfsGfIML2ix"
      },
      "outputs": [],
      "source": [
        "#Get the polymer SMILES from GitHub.\n",
        "csv_url = \"https://raw.githubusercontent.com/S-AJ-H/AIMS26/25478252292fe3bde0e4fb06977ea21c7e05545a/dataset.csv\"\n",
        "df_data = pd.read_csv(csv_url)\n",
        "display(df_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq_WbgLmnBNY"
      },
      "source": [
        "##2. Prepare data for machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.1 Extract and split features and targets"
      ],
      "metadata": {
        "id": "fqKiPE6tadfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Extract smiles and targets (EA)\n",
        "smiles = df_data.loc[:, 'poly_SMI'].values\n",
        "targets = df_data.loc[:, 'EA'].values\n",
        "\n",
        "#instead of using generated fingerprints, we use the SMILES to generate mol objects, then pair the mol objects with the targets y to make \"MoleculeDatapoints\"\n",
        "all_data = [data.MoleculeDatapoint.from_smi(smi, [y]) for smi, y in zip(smiles, targets)]\n",
        "display(all_data[:2])\n",
        "\n",
        "#set up data splitting. Later code is written for easy modification for cross-validation (folds and n_splits variables), but we ignore it in this workbook\n",
        "fold=1\n",
        "n_splits=1                                                                                                  # set only 1 fold\n",
        "train_idx, valid_idx = train_test_split(range(len(smiles)), test_size=0.1, random_state=31, shuffle=True)   # get indices"
      ],
      "metadata": {
        "id": "010JorLJbNc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.2 Define dataloader"
      ],
      "metadata": {
        "id": "xaJTwZsyBT5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataloader(all_data, train_idx, valid_idx, featurizer, batch_size):\n",
        "  # split and featurise the data:\n",
        "  train_data, val_data, _ = data.split_data_by_indices(data=all_data, train_indices=[train_idx], val_indices=[valid_idx])           # Use the 2 lists of indices to split the data.\n",
        "\n",
        "  train_dset = data.MoleculeDataset(train_data[0], featurizer)                                                                      # MoleculeDataset is a Chemprop function that featurises the inputs. We use train_data[0] because there is some nesting\n",
        "  val_dset = data.MoleculeDataset(val_data[0], featurizer)\n",
        "\n",
        "  # scale\n",
        "  scaler = train_dset.normalize_targets()                                                                                           # normalise the targets using StandardScaler (subtract mean, scale to unit variance)\n",
        "  val_dset.normalize_targets(scaler)\n",
        "\n",
        "  # make loaders\n",
        "  train_loader = data.build_dataloader(train_dset, batch_size=batch_size)\n",
        "  val_loader = data.build_dataloader(val_dset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  return train_loader, val_loader, scaler"
      ],
      "metadata": {
        "id": "UfbholocACXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-3oQW3ynBNY"
      },
      "source": [
        "##3. Define, train and validate model\n",
        "\n",
        ">Now our data is ready, its time to use Chemprop. There are 3 main steps:\n",
        "\n",
        "1.   Message passing: Constructs hidden atom representations by passing messages from bond to bond (or atom to atom).\n",
        "2.   Aggregation: Combines the atom representations into a graph level representation (usually atoms -> molecule).\n",
        "3.   Feed-Forward Network (FFN): takes the aggregated representations and make target predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####3. Questions\n",
        "\n",
        "> (a) There is only one place in this model where the pairs of monomers interact with each other - where is it?"
      ],
      "metadata": {
        "id": "V7pyURVaR8ol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3.1 Train and validate model"
      ],
      "metadata": {
        "id": "TyA6jsabBY2K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HvPKzdh_AZU"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "max_epochs = 50                                                                 # default 100\n",
        "batch_size = 256                                                                # default 512\n",
        "dim_h = 100                                                                     # default 300 hidden dimension for graph-level representations. This is the output of the aggregation step and the input of the FFN.\n",
        "ffn_dim = 100                                                                   # default 200 hidden dimension for the FFN.\n",
        "mp_steps = 2                                                                    # default 2\n",
        "mp_drop = 0.0                                                                   # default 0.1\n",
        "ffn_drop = 0.0                                                                  # default 0.1\n",
        "featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
        "metric_list = [nn.metrics.RMSE(), nn.metrics.MAE(), nn.metrics.R2Score()]       # Only the first metric is used for training and early stopping\n",
        "patience = 10\n",
        "\n",
        "results = []                                                                    #for storing all predictions and targets, for all folds\n",
        "fold_r2_scores = []                                                             #for storing all per-fold scores\n",
        "fold_mae_scores = []\n",
        "\n",
        "# train\n",
        "for fold, (train_idx, valid_idx) in enumerate([(train_idx, valid_idx)], 1):\n",
        "  # setup\n",
        "  #=============================================================================\n",
        "  # dataloader\n",
        "  train_loader, val_loader, scaler = dataloader(all_data, train_idx, valid_idx, featurizer, batch_size)\n",
        "\n",
        "  # define (and reset) the model:\n",
        "  mp = nn.BondMessagePassing(d_h=dim_h, bias=False, depth=mp_steps, dropout=mp_drop, activation=nn.utils.Activation.RELU, undirected=False)   # message passing\n",
        "  agg = nn.MeanAggregation()                                                                                                                  # average together all of the hidden node/edge representations to get a graph-level representation.\n",
        "  batch_norm = True                                                                                                                           # normalizes the outputs of the aggregation by re-centering and re-scaling (for better FFN inputs).\n",
        "  output_transform = nn.UnscaleTransform.from_standard_scaler(scaler)                                                                         # define the unscaling function for trainer.predict later\n",
        "  ffn = nn.RegressionFFN(input_dim=dim_h, hidden_dim=ffn_dim, dropout=ffn_drop, n_layers=2, n_tasks=1, output_transform=output_transform)\n",
        "\n",
        "  model = models.MPNN(mp, agg, ffn, batch_norm, metric_list, init_lr = 1e-5, max_lr = 1e-4)                                                   # Defines the complete model structure. Can also change learning rate, optimiser etc. End-to-end trained.\n",
        "\n",
        "  # Configure model checkpointing, early stopping and logging\n",
        "  early_stop = EarlyStopping(monitor=\"val_loss\", patience=patience, mode=\"min\")                                                               # define early stopping conditions\n",
        "  checkpointing = ModelCheckpoint(                                                                                                            # saves trained weights for the model with the lowest validation loss\n",
        "      dirpath=\"checkpoints\",\n",
        "      filename=f\"fold={fold}-best-{{epoch}}-{{val_loss:.2f}}\",\n",
        "      monitor=\"val_loss\",\n",
        "      mode=\"min\",\n",
        "  )\n",
        "  logger = CSVLogger(\"logs\", name=f\"fold_{fold}\", version=0)                                                                                  # saves metrics and losses\n",
        "  # train and validate\n",
        "  #=============================================================================\n",
        "  # train\n",
        "  trainer = pl.Trainer(logger=logger, accelerator=\"auto\", devices=1, max_epochs=max_epochs, callbacks=[checkpointing, early_stop])            # lightning trainer\n",
        "  print(f\"\\nFold {fold}:\\n{'=' * 100}\")\n",
        "  trainer.fit(model, train_loader, val_loader)                                                                                                # model.train() etc is in here\n",
        "  print(f\"\\nFold {fold} complete!\\n\")\n",
        "\n",
        "  # get predictions vs targets\n",
        "  preds = trainer.predict(model, dataloaders=val_loader, ckpt_path=\"best\", weights_only=False)                                                # \"ckpt_path = best\" to load weights with lowest loss\n",
        "  preds_array = np.concatenate([p.cpu().numpy() for p in preds], axis=0).reshape(-1)                                                          # preds from .predict() is already unscaled\n",
        "\n",
        "  # also get the targets for this fold out, so we can calculate per-fold metrics\n",
        "  targets_scaled = np.concatenate([batch.Y.cpu().numpy() for batch in val_loader], axis=0).reshape(-1,1)\n",
        "  targets_array = scaler.inverse_transform(targets_scaled).reshape(-1)                                                                        # need to un-scale targets and flatten\n",
        "\n",
        "  # store predictions and metrics\n",
        "  #=============================================================================\n",
        "  # store predictions\n",
        "  df_fold = pd.DataFrame({\n",
        "      \"original_index\": valid_idx,\n",
        "      \"targets\": targets_array,\n",
        "      \"preds\": preds_array,\n",
        "      \"fold\": fold\n",
        "  })\n",
        "  results.append(df_fold)\n",
        "\n",
        "  #Compute metrics per fold\n",
        "  r2 = r2_score(df_fold[\"targets\"], df_fold[\"preds\"])\n",
        "  mae = mean_absolute_error(df_fold[\"targets\"], df_fold[\"preds\"])\n",
        "  fold_r2_scores.append(r2)                                                                                                                    # collect the per-fold r2 into a single list\n",
        "  fold_mae_scores.append(mae)\n",
        "  print(f\"Fold {fold} metrics: \\nR²={r2:.3f}, MAE={mae:.3f}\\n\")\n",
        "\n",
        "#After all folds:\n",
        "#==========================================================\n",
        "# save all predictions in a dataframe\n",
        "df_results = pd.concat(results, ignore_index=True)\n",
        "df_all = df_data.merge(df_results, left_index=True, right_on=\"original_index\")\n",
        "\n",
        "# Aggregate across folds\n",
        "mean_r2 = np.mean(fold_r2_scores)\n",
        "mean_mae = np.mean(fold_mae_scores)\n",
        "std_r2 = np.std(fold_r2_scores)\n",
        "std_mae = np.std(fold_mae_scores)\n",
        "print(\"\\nFull results:\")\n",
        "print(f\"Mean R²: {mean_r2:.3f} ± {std_r2:.3f}\")\n",
        "print(f\"Mean MAE: {mean_mae:.3f} ± {std_mae:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ebdbmalnBNe"
      },
      "source": [
        "##4. Analyse results\n",
        "\n",
        "Now we have:  \n",
        ">>\n",
        "\n",
        "1.   `df_all`: a dataframe containing our initial info (`df_data`) and our results (`df_results`).\n",
        "2.   Per-fold MAE, R2 metrics in the lists `fold_mae_scores` and `fold_r2_scores`  \n",
        "3. Overall mean metrics and standard deviations (when using multiple folds) in `mean_r2`, `std_r2` etc\n",
        "3.   Per-fold losses per epoch in the file *metrics.csv* in *logs/fold_x/version_0*\n",
        "4.   Per-fold checkpoint files containing the best weights for each fold in the *checkpoints* folder  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 4.1 Print results"
      ],
      "metadata": {
        "id": "3SeSvBYmvO8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print df_all and the MAE:\n",
        "##############################"
      ],
      "metadata": {
        "id": "Tnb98wOSlS9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 4.2 Plot results"
      ],
      "metadata": {
        "id": "3Jc21G8qvGhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract losses per epoch per fold:\n",
        "train_losses_dict = {}                                                          # store the per-fold, per-epoch losses with the key = fold number\n",
        "valid_losses_dict = {}\n",
        "\n",
        "for fold in range(1, n_splits+1):\n",
        "  # extract losses\n",
        "  metrics_path = f\"logs/fold_{fold}/version_{version}/metrics.csv\"\n",
        "  df_metrics = pd.read_csv(metrics_path)\n",
        "  train_losses = df_metrics[\"train_loss_epoch\"].dropna().values\n",
        "  valid_losses = df_metrics[\"val_loss\"].dropna().values\n",
        "\n",
        "  # save to dictionaries\n",
        "  train_losses_dict[fold] = train_losses\n",
        "  valid_losses_dict[fold] = valid_losses\n",
        "\n",
        "# Create subplots\n",
        "n_plots = n_splits + 2  # train/val plots + scatter + bar\n",
        "fig, axes = plt.subplots(3, 4, figsize=(15, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Training vs Validation Loss per fold\n",
        "for fold in range(1, n_splits+1):\n",
        "    ax = axes[fold-1]\n",
        "    ax.plot(train_losses_dict[fold], label=f\"Train Fold {fold}\", alpha=0.7)\n",
        "    ax.plot(valid_losses_dict[fold], label=f\"Valid Fold {fold}\", alpha=0.7)\n",
        "    ax.set_xlabel(\"Epoch\")\n",
        "    ax.set_ylabel(\"MSE Loss\")\n",
        "    ax.set_title(f\"Fold {fold} Losses\")\n",
        "    ax.set_yscale(\"log\")\n",
        "    ax.legend()\n",
        "\n",
        "# Scatter plot: True vs Predicted\n",
        "ax2 = axes[n_splits]\n",
        "for fold in range(1, n_splits+1):\n",
        "    fold_data = df_all[df_all[\"fold\"] == fold]\n",
        "    ax2.scatter(\n",
        "        fold_data[\"targets\"],\n",
        "        fold_data[\"preds\"],\n",
        "        alpha=0.8,\n",
        "        s=5,\n",
        "        label=f\"Fold {fold}\"\n",
        "    )\n",
        "\n",
        "ax2.set_xlabel(\"True EA\")\n",
        "ax2.set_ylabel(\"Predicted EA\")\n",
        "ax2.set_title(\"True vs Predicted EA\")\n",
        "lims = [\n",
        "    min(df_all[\"targets\"].min(), df_all[\"preds\"].min()),\n",
        "    max(df_all[\"targets\"].max(), df_all[\"preds\"].max())\n",
        "]\n",
        "ax2.plot(lims, lims, \"r--\")  # y=x reference\n",
        "ax2.text(0.05, 0.95, f\"R²: {mean_r2:.3f} ± {std_r2:.3f}\",\n",
        "         transform=ax2.transAxes, fontsize=10, verticalalignment='top')\n",
        "ax2.text(0.05, 0.85, f\"MAE: {mean_mae:.3f} ± {std_mae:.3f}\",\n",
        "         transform=ax2.transAxes, fontsize=10, verticalalignment='top')\n",
        "ax2.legend(title=\"Folds\", markerscale=2, loc=\"center left\", bbox_to_anchor=(1.05, 0.5))\n",
        "\n",
        "# Bar chart: MAE per fold\n",
        "ax3 = axes[n_splits+1]\n",
        "cmap = plt.cm.get_cmap(\"tab10\")\n",
        "colors = [cmap(fold-1) for fold in range(1, n_splits+1)]\n",
        "ax3.bar(range(1, n_splits+1), fold_mae_scores, color=colors, edgecolor=\"black\")\n",
        "ax3.set_xlabel(\"Fold\")\n",
        "ax3.set_ylabel(\"MAE\")\n",
        "ax3.set_title(\"MAE per Fold\")\n",
        "ax3.set_xticks(range(1, n_splits+1))\n",
        "\n",
        "# Delete any unused subplots\n",
        "for i in range(n_splits+2, len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BmwEFnuJvnBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Questions\n",
        "\n",
        "\n",
        "1.   Compare the MAE of this model with the \"Fixed representations\" model. What can you conclude?\n",
        "2.   Change the length of the hidden atom representations vector by a factor of 10 smaller and/or larger. How does this impact model MAE?\n",
        "3.   Change the number of message passing steps to 1, and to 5. Explain your observations. How could changing the input SMILES make better use of message passing?\n",
        "4. We split our training and validation data using random splitting. In the context of this polymer SMILES dataset, explain why this may lead to over-optimistic validation performance and poor generalisation to unseen polymers.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tTo_z7x_0n3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Extension Questions\n",
        "\n",
        "\n",
        "1.   Calculate the percentage of polymers for which the model predicts the EA within 0.025 eV. Using google, why might this quantity be a good metric for evaluating model performance? Change the training metric to your new metric and re-train the model.\n",
        "2.   Load the CheMeleon pre-trained weights as seen in the message passing notebook. Use these (a) as an initial starting set of weights which are then fine-tuned and (b) to predict the EAs directly. Does this improve the MAE?\n",
        "\n"
      ],
      "metadata": {
        "id": "4HXqqf7b6O5V"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}