{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPN87wVLeHF1LmwXQY0T9Fu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/S-AJ-H/AIMS26/blob/main/2_Message_passing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Visualising message passing\n",
        "\n",
        "Chemprop uses a graph neural network method in which \"message passing\" is used to learn hidden representations of chemicals. In this example, we visualise how information propagates through a molecule via message passing.\n",
        "\n",
        "You will:\n",
        "   \n",
        "*   Explore how Chemprop calculates initial features of given molecules from SMILES strings.\n",
        "*   Visualise messsage passing by exploring how a small perturbation of the initial features of an atom can propagate through a molecule.\n",
        "\n",
        "Resources:\n",
        ">RDKit:   \n",
        ">https://rdkit.org/docs/index.html\n",
        "\n",
        ">Chemprop:  \n",
        ">https://pubs.acs.org/doi/10.1021/acs.jcim.9b00237  \n",
        ">https://pubs.acs.org/doi/10.1021/acs.jcim.3c01250  \n",
        ">https://chemprop.readthedocs.io/en/latest/"
      ],
      "metadata": {
        "id": "iNpC-nVDVICY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Install chemprop and resources"
      ],
      "metadata": {
        "id": "SkcTwQ6TkHi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install chemprop (~1 min)\n",
        "!pip install chemprop -qq\n",
        "import chemprop\n",
        "print(\"Imported Chemprop version\", chemprop.__version__)\n",
        "\n",
        "# ML\n",
        "from rdkit import Chem                                      # rdkit is used to convert SMILES to molecular graphs (\"mols\")\n",
        "from rdkit.Chem import Draw                                 # Lets us draw molecules\n",
        "from rdkit.Chem.Draw import SimilarityMaps                  # for drawing the partial charges\n",
        "\n",
        "from chemprop import data, featurizers, models, nn          # chemprop is our GNN package\n",
        "from chemprop.models import MPNN                            # Defines the overall MPNN architecture\n",
        "from chemprop.data import BatchMolGraph                     # Batches the MolGraphs\n",
        "from chemprop.nn.message_passing import BondMessagePassing  # Defines the message passing neural network architecture\n",
        "import torch\n",
        "\n",
        "# Misc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "import copy\n",
        "import io\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "uDrcbZGGoJWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Visualising message passing\n",
        "\n",
        "> This section shows how information is shared across a molecule for increasing numbers of message passing steps.\n",
        "> We will use a pre-trained network (https://github.com/JacksonBurns/chemeleon) here; no training is taking place."
      ],
      "metadata": {
        "id": "01w_Bvx6kR6C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Define, draw and featurise the molecule:"
      ],
      "metadata": {
        "id": "4_34F6BOnJAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Define and draw the molecule using smiles and RDkit\n",
        "# ============================================================\n",
        "smiles = \"c1ncc(C)cc1\"\n",
        "molecule = Chem.MolFromSmiles(smiles)\n",
        "display(Draw.MolToImage(molecule))\n",
        "\n",
        "# ============================================================\n",
        "# Featurise using Chemprop\n",
        "# ============================================================\n",
        "# Featurisation converts the molecule (an rdkit class which contains atom types, bond types etc) into a MolGraph (chemprop class containing feature vectors for the atoms and bonds that can be used in ML)\n",
        "featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()   # chemprop module, but based on RDkit. Uses multihot encoding to featurise atoms and bonds.See: https://chemprop.readthedocs.io/en/latest/autoapi/chemprop/featurizers/index.html#chemprop.featurizers.SimpleMoleculeMolGraphFeaturizer\n",
        "mol_graph = featurizer(molecule)\n",
        "\n",
        "print(\"\\nmolecule type:\", type(molecule))\n",
        "print(\"mol_graph type:\", type(mol_graph))\n",
        "print(\"length of atom features:\", mol_graph.V.shape)          # V = atom feature vectors, E = bond feature vectors, edge_index gives graph connectivity.\n",
        "\n",
        "print(\"\\natom features:\")\n",
        "for i, features in enumerate(mol_graph.V):\n",
        "    print(\n",
        "        f\"Atom {i} ({molecule.GetAtomWithIdx(i).GetSymbol()}): \"\n",
        "        f\"{features[:].tolist()}\"\n",
        "    )"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hq8LbFGPpSYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1.1 Questions\n",
        "\n",
        "> (a) Print the size of the atom features and bond features in `mol_graph`. Why are there twice as many edge vectors as atom vectors? Hint: print the edge index.\n",
        "\n",
        "> (b) What does the final value in each atom vector represent? Extra: take a look at the documentation to understand what each bit represents.\n",
        "https://chemprop.readthedocs.io/en/latest/tutorial/python/featurizers/atom_featurizers.html\n",
        "https://chemprop.readthedocs.io/en/latest/autoapi/chemprop/featurizers/bond/index.html"
      ],
      "metadata": {
        "id": "kocGyGwuqjR7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1 Answers\n",
        "\n",
        "> (a)\n",
        "\n",
        "> (b)"
      ],
      "metadata": {
        "id": "kzXPww1kcUyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 1.1 Question answers\n",
        "# ============================================================"
      ],
      "metadata": {
        "id": "26ICIIzoq89s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Set up the message passing\n",
        "\n",
        "> To visualise message passing, we are going to apply 1-3 message passing steps on two molecules with slightly different initial features.\n",
        "> We first carry out the message passing using the features calculated above.\n",
        "> Then, we add a small, arbitrary pertubation to one atom, and re-calculate the hidden features.\n",
        "> By comparing the difference between the two, we can see how information flows."
      ],
      "metadata": {
        "id": "UZHc6C6QnzwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 1.2a. Set up  message passing architectures\n",
        "# ============================================================\n",
        "\n",
        "# get feature dimensions\n",
        "d_v = mol_graph.V.shape[1]\n",
        "d_e = mol_graph.E.shape[1]\n",
        "print(\"number of features per atom, per bond:\", d_v,\",\", d_e)\n",
        "\n",
        "# Set up three message passing architectures with different numbers of steps (\"depths\"). These have randomly initialised weights.\n",
        "mp_1 = BondMessagePassing(d_v=d_v, d_e=d_e, d_h=2048, depth=1, undirected=False)   # d_h = hidden dimension size; 2048 required for our pre-trained weights\n",
        "mp_2 = BondMessagePassing(d_v=d_v, d_e=d_e, d_h=2048, depth=2, undirected=False)\n",
        "mp_3 = BondMessagePassing(d_v=d_v, d_e=d_e, d_h=2048, depth=3, undirected=False)\n",
        "\n",
        "# ============================================================\n",
        "# 1.2b. Import pre-trained weights from the CheMeleon model\n",
        "# ============================================================\n",
        "\n",
        "# import pre-trained weights (takes ~20sec)\n",
        "if not os.path.exists(\"chemeleon_mp.pt\"):\n",
        "    print(\"Downloading CheMeleon weights...\")\n",
        "    urlretrieve(r\"https://zenodo.org/records/15460715/files/chemeleon_mp.pt\",\"chemeleon_mp.pt\",)\n",
        "chemeleon_mp = torch.load(\"chemeleon_mp.pt\", weights_only=False)\n",
        "\n",
        "# load weights into our three message passing architectures (note each message passing step uses the same weights)\n",
        "mp_1.load_state_dict(chemeleon_mp['state_dict'])\n",
        "mp_2.load_state_dict(chemeleon_mp['state_dict'])\n",
        "mp_3.load_state_dict(chemeleon_mp['state_dict'])"
      ],
      "metadata": {
        "id": "KrO1npx8AK02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1.2 Questions\n",
        "\n",
        "> (a) Why do we use BondMessagePassing instead of AtomMessagePassing? Hint: look at the papers linked at the top."
      ],
      "metadata": {
        "id": "NM--V2p6BnKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Compute hidden embeddings\n",
        "\n",
        "> Using our pre-loaded weights, we now calcuate the hidden embeddings"
      ],
      "metadata": {
        "id": "dzRi5WoGFjVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 1.3a. Compute baseline embeddings\n",
        "# ============================================================\n",
        "batch_graph = BatchMolGraph([mol_graph])                                        #chemprop message passing requires batches, even for a single MolGraph\n",
        "with torch.no_grad():                                                           #calculate hidden features for each atom\n",
        "    h1 = mp_1(batch_graph)\n",
        "    h2 = ################################         # hidden representations with 2 message passing steps\n",
        "    h3 = ################################         # hidden representations with 3 message passing steps\n",
        "\n",
        "h_baseline = [h1, h2, h3]                                                       #list of features (tensors)\n",
        "\n",
        "# ============================================================\n",
        "# 1.3b. Perturb one atom's initial features\n",
        "# ============================================================\n",
        "source_atom = 0                                                                 #choose the left-most carbon\n",
        "epsilon = 1e-2                                                                  #define an arbirary perturbation\n",
        "\n",
        "mol_graph_pert = copy.deepcopy(mol_graph)                                       #copy the original features into a new MolGraph\n",
        "\n",
        "mol_graph_pert.V[source_atom] = mol_graph_pert.V[source_atom] + epsilon         #add the perturbation to all atom features in atom #0.\n",
        "print(\"initial features:\\n\", mol_graph.V[0])\n",
        "print(\"\\nPerturbed initial features:\\n\", mol_graph_pert.V[0])\n",
        "\n",
        "# ============================================================\n",
        "# 1.3c. Compute perturbed embeddings\n",
        "# ============================================================\n",
        "batch_graph_pert = BatchMolGraph([mol_graph_pert])\n",
        "with torch.no_grad():\n",
        "    h1_p = mp_1(batch_graph_pert)\n",
        "    h2_p = ################################     # perturbed hidden representations with 2 message passing steps\n",
        "    h3_p = ################################     # perturbed hidden representations with 3 message passing steps\n",
        "\n",
        "h_perturbed = [h1_p, h2_p, h3_p]\n",
        "\n",
        "# ============================================================\n",
        "# 1.3d. Compute the difference between the original and the perturbed:\n",
        "# ============================================================\n",
        "deltas = []\n",
        "for h_b, h_p in zip(h_baseline, h_perturbed):\n",
        "    delta = torch.norm(h_p - h_b, dim=1)                                        # calculate L2 norm; collapses the 2048-dimensional vector into a single scalar per atom\n",
        "    deltas.append(delta.cpu().numpy())"
      ],
      "metadata": {
        "id": "v9wYXDAEgWPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Plot the difference\n",
        "\n",
        "> The difference shows how that small perturbation to the features of the nitrogen propogate through the molecule."
      ],
      "metadata": {
        "id": "3_hHVAe1FiEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate colour scale\n",
        "all_vals = np.concatenate(deltas)\n",
        "vmin, vmax = np.min(all_vals), np.max(all_vals)\n",
        "\n",
        "def draw_molecule(mol, values, vmin, vmax, cmap_name, size=(300,300)):\n",
        "    # values\n",
        "    vals = np.array(values)\n",
        "    vals = (vals - vmin) / (vmax - vmin + 1e-12)                                # 1e-12 prevents possible zero denominator\n",
        "    vals = vals **0.5                                                           # colour scaling\n",
        "\n",
        "    # colours\n",
        "    cmap = matplotlib.colormaps.get_cmap(cmap_name)\n",
        "    atom_colors = {i: tuple(cmap(v)[:3]) for i, v in enumerate(vals)}           # RDKit wants {atom_idx: (R,G,B)}\n",
        "\n",
        "    # other options\n",
        "    drawer = Draw.MolDraw2DCairo(size[0], size[1])\n",
        "    opts = drawer.drawOptions()\n",
        "    opts.addAtomIndices = True\n",
        "    opts.highlightBondWidthMultiplier = 0\n",
        "    drawer.DrawMolecule(mol, highlightAtoms=list(atom_colors.keys()), highlightAtomColors=atom_colors)\n",
        "\n",
        "    drawer.FinishDrawing()\n",
        "    return drawer.GetDrawingText()"
      ],
      "metadata": {
        "id": "PvRjYes1aSj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles = [\"after 1 step\", \"after 2 steps\", \"after 3 steps\"]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
        "\n",
        "for ax, title, delta_vals in zip(axes, titles, deltas):\n",
        "\n",
        "    png_bytes = draw_molecule(\n",
        "        molecule,\n",
        "        delta_vals,\n",
        "        vmin=vmin,\n",
        "        vmax=vmax,\n",
        "        cmap_name=\"plasma\"\n",
        "    )\n",
        "\n",
        "    img = plt.imread(io.BytesIO(png_bytes))\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(title)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e-KfW_g4E_zZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1.4 Questions\n",
        "\n",
        "> (a) Why are atoms #2 and #5 the same colour after 1 pass, but different colours from each other after 2 and 3 passes?  \n",
        "\n",
        "> (b) Why does message passing satisfy node permutation equivariance?\n",
        "\n",
        "> (c) Think about our polymer system again. We use two monomers to represent the alternating polymer chain (A-B-A-B-A-B-...). Comment on how this representation might be an issue for a message passing network. What could we do to rectify this?\n"
      ],
      "metadata": {
        "id": "SC1nc3x2FsQv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1.4 Answers\n",
        "\n",
        "> (a)  \n",
        "\n",
        "> (b)  \n",
        "\n",
        "> (c)  "
      ],
      "metadata": {
        "id": "LSIJtAdvFsFw"
      }
    }
  ]
}